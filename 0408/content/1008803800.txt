The supercomputer game has traditionally been the playground of giants -- government agencies and a handful of major corporations.But cloud computing is leveling even this elite realm of technology, a development underlined by an announcement at a conference on Thursday. A 20-person company, Cycle Computing, a leader in supercomputer software, recently lashed together a massive supercomputing cluster, with 50,000 processors, on Amazon Web Services to do drug compound simulations. Its software was essentially the operating system, tapping resources from several Amazon data centers.The simulation applications for drug discovery created by two other small companies, Schrodinger and Nimbus Discovery, ran on top of Cycle's cluster-managing software. That software bundle performed a daunting simulation of 21 million chemical compounds to see if they would bind with a protein target. That run ate up the equivalent of 12.5 processor years, but it was completed in less than three hours. The computing cost was less than $4,900 a hour."This enables small companies and any researcher that has a grant to do science that they could never do before," Jason Stowe, chief executive of Cycle Computing, said in an interview.The economics are striking, but so is the new approach to scientific discovery and exploration. In the past, even major pharmaceutical and biotechnology companies, with internal computing clusters, would typically develop models that virtually tested some portion of the possible chemical combinations and protein targets -- not the 21 million, as in the Cycle-Schrodinger-Nimbus collaboration. "The technology allows researchers to leave no sample unconsidered," Mr. Stowe said.The project announcement was made at the Amazon Web Services conference in New York. It is further evidence of the remote computing -- or cloud -- advance into a field known for its centralized supercomputer centers. Last fall, an Amazon Web Services cluster ranked 42 in the annual top 500 supercomputers in the world.Supercomputing, according to Mr. Stowe, is undergoing a rapid evolution that echoes the transformation in data analysis, made possible by the accelerating surge in digital data and new computing tools. Government science officials emphasized that trend at a Washington conference last month, in which several federal agencies announced research initiatives.Data analysis has been opened up to finding new patterns and insights in the so-calledBig Data. Supercomputing focuses on simulations, but the two are related and that, Mr. Stowe says, represents a next stage in the march ofBig Data.Data analysis, Mr. Stowe said, looks for correlations and patterns in the data. Noticing a surge in a subject or sentiment in Twitter messages, for example.The next step, Mr. Stowe said, is going to be "how to get a Twitter avalanche going, how to make people have this sentiment about my brand. That's a simulation problem."This is a more complete version of the story than the one that appeared in print.Jason Stowe, Chief Executive of Cycle Computing, Spoke On Supercomputing Thursday at an Amazon Event in Manhattan. (Photograph by Scott Kowalchyk/Orange Photography)